GPU Environment Diagnostic Tool - Flask Context
Timestamp: 2025-05-28 07:08:44.394054

============================================================
 Python Environment Check
============================================================
Python Version: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
Python Executable: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\Scripts\python.exe
Platform: Windows-10-10.0.26100-SP0
Architecture: ('64bit', 'WindowsPE')
Process ID: 17760
Working Directory: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server

============================================================
 CUDA Environment Check
============================================================
CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8
CUDA_HOME: NOT SET
CUDA_ROOT: NOT SET
CUDA_VISIBLE_DEVICES: NOT SET
CUDA_DEVICE_ORDER: NOT SET
PATH: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\llama_cpp\lib;C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\llama_cpp\lib;C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\Scripts;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\libnvvp;;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Windows\System32\OpenSSH\;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\Git\cmd;C:\Program Files\nodejs\;C:\Program Files (x86)\Windows Kits\10\Windows Performance Toolkit\;C:\Program Files\dotnet\;C:\Program Files (x86)\Microsoft SQL Server\160\DTS\Binn\;C:\Program Files (x86)\Microsoft SQL Server\160\Tools\Binn\;C:\Program Files\Microsoft SQL Server\160\Tools\Binn\;C:\Program Files\Microsoft SQL Server\Client SDK\ODBC\170\Tools\Binn\;C:\Program Files\Microsoft SQL Server\160\DTS\Binn\;C:\WINDOWS\system32;C:\WINDOWS;C:\WINDOWS\System32\Wbem;C:\WINDOWS\System32\WindowsPowerShell\v1.0\;C:\WINDOWS\System32\OpenSSH\;C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.1.0\;C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR;C:\Users\soulo\AppData\Local\Programs\Python\Python310\Scripts\;C:\Users\soulo\AppData\Local\Programs\Python\Python310\;C:\Users\soulo\AppData\Local\Microsoft\WindowsApps;C:\Users\soulo\AppData\Local\GitHubDesktop\bin;C:\Users\soulo\AppData\Roaming\npm;C:\Users\soulo\miniconda3;C:\Users\soulo\miniconda3\Library\mingw-w64\bin;C:\Users\soulo\miniconda3\Library\usr\bin;C:\Users\soulo\miniconda3\Library\bin;C:\Users\soulo\miniconda3\Scripts;C:\Users\soulo\AppData\Local\Programs\Microsoft VS Code\bin;;C:\Users\soulo\.cache\lm-studio\bin
LD_LIBRARY_PATH: NOT SET

nvidia-smi: AVAILABLE
GPU Info: | GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
GPU Info: | Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
GPU Info: |   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |
GPU Info: |  GPU   GI   CI              PID   Type   Process name                        GPU Memory |

============================================================
 Process Context Check
============================================================
Current User: soulo
User Domain: AJS_LAPTOP
Virtual Environment: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv
CUDA-related paths in PATH:
  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\bin
  C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\libnvvp
  C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common
  C:\Program Files\NVIDIA Corporation\Nsight Compute 2025.1.0\
  C:\Program Files\NVIDIA Corporation\NVIDIA app\NvDLISR

============================================================
 GPU Memory Check
============================================================
GPU 0: Total=8188MB, Used=188MB, Free=7761MB

============================================================
 llama-cpp-python Installation Check
============================================================
llama-cpp-python: IMPORTED SUCCESSFULLY
Version: 0.3.8
Module Path: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\llama_cpp\__init__.py

Testing GPU availability...
Test model exists: C:/Users/soulo/.cache/lm-studio/models/TheBloke/Kunoichi-7B-GGUF/kunoichi-7b.Q6_K.gguf
Attempting to create Llama instance with GPU layers...
âœ“ GPU Test: SUCCESS - Llama instance created with GPU layers

============================================================
 Execution Context Test
============================================================
Script Context: server.py
Execution Mode: Flask endpoint
Call Stack Depth: 18
Call Stack:
  0: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\server.py:515 in run_execution_context_test
  1: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\server.py:530 in gpu_diagnostic
  2: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\flask\app.py:902 in dispatch_request
  3: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\flask\app.py:917 in full_dispatch_request
  4: C:\Users\soulo\Organized\Personal\My Projects\MyLLMApp\server\venv\lib\site-packages\flask\app.py:1511 in wsgi_app

============================================================
 Flask Context Diagnostic Complete
============================================================
